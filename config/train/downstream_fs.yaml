trainer:
  _target_: lightning.pytorch.Trainer
  log_every_n_steps: 200
  devices: 1
  accelerator: cpu
  max_epochs: 250
  min_epochs: 70
  limit_val_batches: 1.0
  limit_train_batches: 1.0
  check_val_every_n_epoch: 2

batch_size: null

optimizer_config:
  _target_: torch.optim.Adam
scheduler_config:
  _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
  T_0: 2
  T_mult: 2
loss:
  _target_: torch.nn.CrossEntropyLoss
  ignore_index: 0

slurm_restart: false
